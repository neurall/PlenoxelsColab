{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Plenoxels.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neurall/PlenoxelsColab/blob/main/Plenoxels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an attempt to make running in Colab cloud GPU possible for the wonderfull breakthrough that is Plenoxels made by fantastic team of incredibly talented  \n",
        "\n",
        "# Plenoxels Authors: (Alex Yu * Sara Fridovich-Keil * Matthew Tancik Qinhong Chen Benjamin Recht Angjoo Kanazawa UC Berkeley * Equal contribution)  \n",
        "\n",
        "Github:            https://github.com/sxyu/svox2  \n",
        "Website and video: https://alexyu.net/plenoxels  \n",
        "arXiv:             https://arxiv.org/abs/2112.05131  \n",
        "\n",
        "Their achievement of shortening training from days to minutes is nothing short of extreaordinary. Incredible feat and wonderfull insight.\n",
        "\n",
        "But due to recent shortage of gpus on market simple instant and easily accesible GPU cloud based workflow seems to be more important to fast research iteration than ever.\n",
        "<br>\n",
        "\n",
        "This first version seems to work at least on Colab Pro providing 16g gpu and with high mem option enabled(32g ram) to fit and train M60 dataset (Colab Pro is 10$ a month which is price of 1 hamburger)  \n",
        "<br>\n",
        "This colab will currently sadly not yet work on free colab (but deffinitely can soon, see idea proposed below?) instance due to size of datasets. And niether will it probably reasonably well work (if you reduce res it will fit in gpu mem but output typically will be unusable) on any gpu commonly at your pc like 10g 3080 or 11g 1080   \n",
        "\n",
        "# Free colab has just 12g ram 11g (P8) gpu or 15g (t4?) gpu and this svox2 variant needs at least 27g ram and at least 16g gpu (p100?) for training datasets of similar size as cool M60 Tank dataset from my observations so far  \n",
        "\n",
        "Hmm when you think about it These Larger datasets should be splitable to smaller ones fitting 4-24g gpus by estimated camera locations from bundle adjustment colmap files that datasets already have?  \n",
        "<br>\n",
        "Multi gpu (or multipass for free colab?) can than in theory work like this.  \n",
        "\n",
        "Say you have 2 x 11g gpus. Split dataset photos to 2 x 2 chunks ABCD by estimated cam positions that datasets already have  \n",
        "<br>\n",
        "Then train on as many gpus in paralell as you want  \n",
        "<br>\n",
        "pass1 train individual scene fragments\n",
        "<br>\n",
        "gpu1:AB gpu2:CD  \n",
        "<br>\n",
        "pass2 to solve underrepresented voxels from border regions of chunks to allow good merge of seams \n",
        "<br>\n",
        "gpu1:BC gpu2:DA    \n",
        "<br>\n",
        "merge pass1 and pass2  \n",
        "<br>\n",
        "Datasets:\n",
        "NeRF-synthetic and front facing llff: \n",
        "https://drive.google.com/drive/folders/128yBriW1IG_3NJ5Rp7APSTZsJqdJdfc1  \n",
        "Processed Tanks and temples dataset (with background): \n",
        "https://drive.google.com/file/d/1PD4oTP4F8jTtpjd_AQjCsL4h8iYFCyvO  \n",
        "Real Lego capture: \n",
        "https://drive.google.com/file/d/1PG-KllCv4vSRPO7n5lpBjyTjlUyT8Nag  \n",
        "Pretrained checkpoints (good if you cant train?): \n",
        "https://drive.google.com/drive/folders/1SOEJDw8mot7kf5viUK9XryOAmZGe_vvE  \n",
        "\n"
      ],
      "metadata": {
        "id": "Zbg9iHgVQjfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sadly. my 3080 while it more than twice as fast as Colab Pro is sitting iddle due to just 10g gpu mem\n",
        "# So let's see what gpu colab given us (16g gpu mem is minumum for M60 tank sample dataset training and is given on Colab Pro instances).\n",
        "from psutil import virtual_memory\n",
        "gpu_info = !nvidia-smi \n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('BEWARE!!! Not connected to a GPU. Nothing will work')\n",
        "else:\n",
        "  print(gpu_info,'\\n\\nBEWARE!!! GPUs with less than 16g will fail with out of memory on M60 training near the end of training.')\n",
        "\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('\\nYour runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('BEWARE!!! Not using a high-RAM runtime. M60 training will fail on out of general memory')\n",
        "else:\n",
        "  print('Great. You are using a high-RAM runtime! 27g is needed to train M60 \\n')\n",
        "!python --version"
      ],
      "metadata": {
        "id": "4Eho4tgYSAv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxGfk51EjgiC"
      },
      "outputs": [],
      "source": [
        "#comment capture out to see cell outputs first time. I personally consider it unecessary super long distracting spam afterwards and cell execution done checkmark is all I need.\n",
        "%%capture \n",
        "import os\n",
        "\n",
        "%cd '/content'\n",
        "if not os.path.exists('svox2'):\n",
        "  !git clone https://github.com/sxyu/svox2.git  &> /dev/null\n",
        "\n",
        "  # patch and make py sources again compatible with CoLab (python 3.7) by removing 3.8 specific syntax from two lines\n",
        "  !sed -E -i \"s/\\{minv=:/minv=\\{minv:/g\"    /content/svox2/opt/opt.py \n",
        "  !sed -E -i \"s/\\{meanv=:/meanv=\\{meanv:/g\" /content/svox2/opt/opt.py \n",
        "  !sed -E -i \"s/\\{maxv=:/maxv=\\{maxv:/g\"    /content/svox2/opt/opt.py \n",
        "  !sed -E -i \"s/\\{minv=:/minv=\\{minv:/g\"    /content/svox2/opt/render_imgs.py \n",
        "  !sed -E -i \"s/\\{meanv=:/meanv=\\{meanv:/g\" /content/svox2/opt/render_imgs.py \n",
        "  !sed -E -i \"s/\\{maxv=:/maxv=\\{maxv:/g\"    /content/svox2/opt/render_imgs.py \n",
        "  \n",
        "  # there is no point in slow conda and especiall this multi env dance in throwavay colab env anyway and most packages are installed already.\n",
        "  # And if we stick to py 3.7 pytorch cudatoolkit and most of environment.yml etc. is already installed and ready here so install just 4 missing packages\n",
        "\n",
        "  !pip install imageio-ffmpeg\n",
        "  !pip install ipdb\n",
        "  !pip install lpips\n",
        "  !pip install pymcubes\n",
        "\n",
        "  # this helps to lower gpu alloc waste and in turn allows fitting 16g gpu mem typically present in cloud gpus as max\n",
        "  # ie I was last time 20mb short instead of 2g short on gpu mem\n",
        "  %env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:21\n",
        "\n",
        "%cd svox2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use gdrive to cache compiled pytorch wheel and checkpoint after training so next time colab runtime resets and forgets all files next bootstrap is fast\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kaYiQzjzApuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile and install pytorch wheel is soooo sloooow. So we compile just once cache on gdrive and then just reinstall on each runtime restart\n",
        "# we cache whl for each  gpu you encounter and save whls to gdrive in dirs with gpu names since they can and will vary\n",
        "import os\n",
        "from google.colab import files\n",
        "%cd /content/svox2\n",
        "\n",
        "# grab currenly assigned gpu model name (P100-16gb etc.)\n",
        "gpuname = !nvidia-smi -L\n",
        "gpuname = str(gpuname).replace('PCIE-','').split('Tesla ')[1].split(' ')[0]\n",
        "whlname = 'svox2-0.0.1.dev0+sphtexcub.lincolor.fast-cp37-cp37m-linux_x86_64.whl'\n",
        "whlpath = '/content/drive/MyDrive/'+gpuname+'/'+whlname\n",
        "print(gpuname)\n",
        "\n",
        "# compile this whl just once first time to obtain and cache it on gdrive\n",
        "if not os.path.exists(whlpath):\n",
        "  !apt install ninja-build\n",
        "  %env MAX_JOBS=4\n",
        "  !python setup.py bdist_wheel &> /dev/null\n",
        "  !mkdir /content/drive/MyDrive/{gpuname}\n",
        "  !cp ./dist/{whlname} {whlpath}\n",
        "\n",
        "# install cached whl next time env is reset to skip costly recompilation\n",
        "if os.path.exists(whlpath):\n",
        "  !pip install {whlpath} --force-reinstall"
      ],
      "metadata": {
        "id": "gUqq8knldYD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download super cool tank dataset if not dir already present\n",
        "%%capture \n",
        "%cd /content/svox2\n",
        "import os\n",
        "dataset_gdrive_ids={'TanksAndTempleBG':'1PD4oTP4F8jTtpjd_AQjCsL4h8iYFCyvO', # Datasets: from gdrive folder where id is last folder name in url: https://drive.google.com/drive/folders/128yBriW1IG_3NJ5Rp7APSTZsJqdJdfc1\n",
        "                    'nerf_llff_data'  :'16VnMcF1KJYxN9QId6TClMsZRahHNMW5g',\n",
        "                    'nerf_real_360'   :'1jzggQ7IPaJJTKx9yLASWHrX8dXHnG5eB',\n",
        "                    'nerf_synthetic'  :'18JxhpWD-4ZmuFKLzKlAw-w5PpzZxXOcG',\n",
        "                    'nerf_example'    :'1xzockqgkO-H3RCGfkZvIZNjOnk3l7AcT',\n",
        "                    'lego_real_night_radial':'1PG-KllCv4vSRPO7n5lpBjyTjlUyT8Nag'}\n",
        "dataset = 'TanksAndTempleBG'\n",
        "if not os.path.exists(dataset):\n",
        "  !gdown --id {dataset_gdrive_ids[dataset]}  &> /dev/null\n",
        "  !tar -xvf {dataset}.tar.gz  &> /dev/null\n",
        "  !rm  -rf  {dataset}.tar.gz"
      ],
      "metadata": {
        "id": "qxqjozeh2oy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# launch actual training (27g ram and 16g gpu for M60 dtataset needed)\n",
        "%cd /content/svox2/opt\n",
        "!./launch.sh m60 0 ../TanksAndTempleBG/M60 -c configs/tnt.json"
      ],
      "metadata": {
        "id": "eG6WJ_aiV7KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since training runs detached we can peek at output on demand here when needed\n",
        "# stop this manually when it ends thou!!! so next cells can run (look for \" final save \" text in output)\n",
        "%cd /content/svox2/opt\n",
        "!tail -f ckpt/m60/log"
      ],
      "metadata": {
        "id": "RzGaIuArWuBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets see our final resulting trained checkpoint file size when done . official one is 4G\n",
        "!ls -la /content/svox2/opt/ckpt/m60/ckpt.npz"
      ],
      "metadata": {
        "id": "DvAZ6a-xsaEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# backup our expensively trained checkpoint to gdrive for future rendering tests if needed \n",
        "%%capture \n",
        "import os\n",
        "%cd /content/svox2/opt\n",
        "if os.path.exists('/content/svox2/opt/ckpt/m60/ckpt.npz'):\n",
        "  !cp -R /content/svox2/opt/ckpt //content/drive/MyDrive/ckpt\n"
      ],
      "metadata": {
        "id": "oGJD2CrXbHOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (Sadly even thou colab pro has 16g it is still just 16g gpu)\n",
        "# SO. If the damn training for too large datasets keeps failing with: out of memory even for cloud typically 12g or 16g gpus \n",
        "#\n",
        "# Then. Luckily. We can still at least try download already trained checkpoints (thx. to paper authors ;D yay)\n",
        "# And at least start playing with rendering images from various angles\n",
        "#\n",
        "# BUT BEWARE this is 11g gz download if enabled\n",
        "# AND ALSO: if 3-4 downloads happen per 24h of this 11g large file from gdrive, which is highly plausible given usage in this colab. \n",
        "# Then google colab will block further downloads via this gdown api at this particular day for 24h\n",
        "# If that happens. You can still supposedly download it via browser and curl/wget or upload it here by other means I guess?\n",
        "\n",
        "%cd /content/svox2/opt\n",
        "import os\n",
        "\n",
        "# change this to True to enable pretrained checkpoints download. beware again 11g\n",
        "if False:\n",
        "  !mv ckpt ckpt_our\n",
        "  if not os.path.exists('ckpt_tnt.tar.gz'): \n",
        "    !gdown --id 1v9xb5Sd3ulofwNUynC71I_fdwnSLnFhS \n",
        "  !tar -xvf ckpt_tnt.tar.gz  &> /dev/null\n",
        "  !rm  -rf  ckpt_tnt.tar.gz # delete this huge 11g file as fast as possible\n",
        "  !ls -la tnt_equirectlin_fasttv_autoscale/M60/ckpt.npz # check ckpt size for m60. should be around 4g\n",
        "  !mv tnt_equirectlin_fasttv_autoscale ckpt"
      ],
      "metadata": {
        "id": "eIUHJyMrQNxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finally lets synthetize some sample images from various angles (typically 360 orbit around object) from trained checkpoint / model\n",
        "%cd /content/svox2/opt\n",
        "!python -u render_imgs.py ckpt/m60 ../TanksAndTempleBG/M60 "
      ],
      "metadata": {
        "id": "53KZA1Miqzp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transfer 3m jpgs in zip is more practical than 40mb pngs or hard to inspect mp4 with too aggresive compression\n",
        "%%capture \n",
        "%cd /content/svox2/opt/ckpt/m60/test_renders\n",
        "!for i in *.png; do ffmpeg -i \"$i\" \"${i%.*}.jpg\" &> /dev/null ; done \n",
        "!find . -type f -iname \\*.png -delete\n",
        "%cd /content/svox2/opt\n",
        "!zip -r m60.zip /content/svox2/opt/ckpt/m60/test_renders &> /dev/null "
      ],
      "metadata": {
        "id": "T_DzNH_vj5Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy resulting images to special in html cell visible dir \n",
        "%%capture \n",
        "!cp /content/svox2/opt/ckpt/m60/test_renders/*.* /usr/local/share/jupyter/nbextensions/ &> /dev/null\n",
        "!cp m60.zip /usr/local/share/jupyter/nbextensions/ &> /dev/null"
      ],
      "metadata": {
        "id": "y9F8BfCNZUxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show some sample synthetized images\n",
        "%%html\n",
        "<a href src='/nbextensions/m60.zip' download>Download Images</a><br>\n",
        "<img width=\"100%\" src='/nbextensions/0000.jpg' />\n",
        "<img width=\"100%\" src='/nbextensions/0020.jpg' />\n",
        "<img width=\"100%\" src='/nbextensions/0031.jpg' />"
      ],
      "metadata": {
        "id": "ZzAMVhVQYZX2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}