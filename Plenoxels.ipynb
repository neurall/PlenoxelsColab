{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neurall/PlenoxelsColab/blob/main/Plenoxels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbg9iHgVQjfs"
      },
      "source": [
        "This first version seems to work at least on Colab Pro providing 16g gpu and with high mem option enabled(32g ram) to fit and train 512 size of voxel cube (Colab Pro is 10$ a month which is price of 1 hamburger)  or connect colab to better gpu and ram via gcloud https://drive.google.com/file/d/1ijawhI6AuPXxWhLu8flkrHZPTu3o_zF0/view\n",
        "<br>\n",
        "\n",
        "If you want. You can run it even on your local 10g 3080. Just delete in configs [512,512,512] that is there for 16g gpus to run in consumer gpus [256,256,256]= max 10g gpu mem usage.  \n",
        "Results will be much lower res. But at least you can now play with it locally now.\n",
        "<br>\n",
        "\n",
        "You can fork this colab at https://github.com/neurall/PlenoxelsColab/blob/main/Plenoxels.ipynb\n",
        "\n",
        "It is an attempt to make running in Colab cloud GPU possible for the wonderfull breakthrough that is Plenoxels made by fantastic team of incredibly talented  \n",
        "\n",
        "# Plenoxels Authors: (Alex Yu * Sara Fridovich-Keil * Matthew Tancik Qinhong Chen Benjamin Recht Angjoo Kanazawa UC Berkeley * Equal contribution)  \n",
        "\n",
        "Github:            https://github.com/sxyu/svox2  \n",
        "Website and video: https://alexyu.net/plenoxels  \n",
        "arXiv:             https://arxiv.org/abs/2112.05131  \n",
        "\n",
        "Their achievement of shortening voxel extraction from days to minutes is nothing short of extreaordinary. Incredible feat and wonderfull insight.\n",
        "\n",
        "But due to recent shortage of gpus on market.  \n",
        "<br>\n",
        "Simple instant and easily accesible GPU cloud based workflow now seems to be more important to fast research iteration than ever.  \n",
        "<br>\n",
        "This colab will currently sadly not yet work on free colab with voxel size 512\n",
        "\n",
        "Perhaps we can train four quadrants in [256,256,256]  voxel sub cubes in separate passes instead of one [512,512,512] pass in config? But that would require change scene center and bounds somehow for each pass ?\n",
        "\n",
        "# Free colab has just 12g ram 11g (P8) gpu or 15g (t4?) gpu and this svox2 variant needs at least 27g ram and at least 16g gpu  for fitting 512 voxel size  \n",
        "\n",
        "<br>\n",
        "Datasets:\n",
        "NeRF-synthetic and front facing llff: \n",
        "https://drive.google.com/drive/folders/128yBriW1IG_3NJ5Rp7APSTZsJqdJdfc1  \n",
        "Processed Tanks and temples dataset (with background): \n",
        "https://drive.google.com/file/d/1PD4oTP4F8jTtpjd_AQjCsL4h8iYFCyvO  \n",
        "Real Lego capture: \n",
        "https://drive.google.com/file/d/1PG-KllCv4vSRPO7n5lpBjyTjlUyT8Nag  \n",
        "Pretrained checkpoints (good if you cant train?): \n",
        "https://drive.google.com/drive/folders/1SOEJDw8mot7kf5viUK9XryOAmZGe_vvE  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Eho4tgYSAv2"
      },
      "outputs": [],
      "source": [
        "# Sadly. my 3080 while it is more than twice as fast as Colab Pro, it is still sitting idle due to just 10g gpu mem ending training attempts with out of gpu mem errors\n",
        "# So let's see what gpu colab given us in cloud (16g gpu mem is minumum for M60 tank sample dataset training and is given on Colab Pro instances).\n",
        "from psutil import virtual_memory\n",
        "\n",
        "gpuname = !nvidia-smi -L\n",
        "gpuname = str(gpuname).replace('PCIE-','').split('Tesla ')[1].split(' ')[0]\n",
        "\n",
        "print(gpuname)\n",
        "\n",
        "gpu_info = !nvidia-smi \n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('ERROR!!! Not connected to a GPU. Nothing will work')\n",
        "else:\n",
        "  gpu_mem = int(str(gpu_info).split('MiB / ')[1].split('MiB')[0])\n",
        "  print('You got '+str(gpu_mem)+' gpu mem ')\n",
        "  if gpu_mem < 16000:\n",
        "    print(gpu_info,'\\n\\nBEWARE!!! GPUs with less than 16g will fail with out of memory error on M60 dataset or bigger near training end.')\n",
        "  else:\n",
        "    print('which seems enough.')\n",
        "\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('BEWARE!!! Not using a high-RAM runtime of Colab Pro. M60 training will fail on out of system memory which is just 12 g on Colab Free')\n",
        "else:\n",
        "  print('Great. You are using a high-RAM runtime '+str(int(ram_gb))+'Gb ! 27g is needed to train example M60 Tank dataset\\n')\n",
        "\n",
        "# one day colab will hopefully move to python 3.8 and higher\n",
        "!python --version\n",
        "\n",
        "# for faster compiles later\n",
        "!apt install -y -qq  ninja-build  &> /dev/null\n",
        "\n",
        "import multiprocessing\n",
        "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
        "%env MAX_JOBS={cores}\n",
        "\n",
        "# make sure that colmap is ready if needed to work on our own images later\n",
        "!apt install colmap &> /dev/null\n",
        "colmap_version = !colmap -h\n",
        "print (colmap_version[0])\n",
        "\n",
        "# this is key to fit in gpu mem. helps to lower gpu fragmentation alloc waste and in turn allows fitting 16g gpu mem typically present in cloud gpus as max\n",
        "# ie I was last time 20mb short instead of 2g short on gpu mem\n",
        "%env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:21\n",
        "\n",
        "#comment capture out to see cell outputs first time. I personally consider it unecessary super long distracting spam afterwards and cell execution done checkmark is all I need.\n",
        "#%%capture \n",
        "\n",
        "import os\n",
        "%cd '/content'\n",
        "if not os.path.exists('svox2'):\n",
        "  !git clone https://github.com/sxyu/svox2.git  &> /dev/null\n",
        "\n",
        "  # patch and make py sources again compatible with CoLab (python 3.7) \n",
        "  # by removing completely unnecesary 3.8 specific syntaxctic sugar from two lines\n",
        "  !sed -E -i \"s/\\{minv=:/minv=\\{minv:/g\"    /content/svox2/opt/opt.py \n",
        "  !sed -E -i \"s/\\{meanv=:/meanv=\\{meanv:/g\" /content/svox2/opt/opt.py \n",
        "  !sed -E -i \"s/\\{maxv=:/maxv=\\{maxv:/g\"    /content/svox2/opt/opt.py \n",
        "  !sed -E -i \"s/\\{minv=:/minv=\\{minv:/g\"    /content/svox2/opt/render_imgs.py \n",
        "  !sed -E -i \"s/\\{meanv=:/meanv=\\{meanv:/g\" /content/svox2/opt/render_imgs.py \n",
        "  !sed -E -i \"s/\\{maxv=:/maxv=\\{maxv:/g\"    /content/svox2/opt/render_imgs.py \n",
        "\n",
        "%cd svox2\n",
        "\n",
        "# There is no point in slow conda and multi env dance in this throwavay colab env anyway plus most packages from environment.yml are installed already.\n",
        "# So if we stick to colabs py 3.7 then biggest and most complex ones like pytorch cudatoolkit and most of environment.yml requirements is already present \n",
        "# and we need to install just 4 missing packages. \n",
        "# In short. By sticking to py 3.7 this colab can be restarted from factory reset state very fast without endless and useless huge long reinstalls\n",
        "\n",
        "!pip install imageio-ffmpeg &> /dev/null\n",
        "!pip install ipdb           &> /dev/null\n",
        "!pip install lpips          &> /dev/null\n",
        "!pip install pymcubes       &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kaYiQzjzApuo"
      },
      "outputs": [],
      "source": [
        "# To make env restarts even faster. It is perhaps good idea to use gdrive to cache once compiled pytorch wheel and later even checkpoint after training \n",
        "# so next time colab runtime resets and forgets all files next bootstrap is fast\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gUqq8knldYD2"
      },
      "outputs": [],
      "source": [
        "# Because compile and install of pytorch wheel is soooo sloooow. We compile it just once first time we run this colab,\n",
        "# And then cache it on gdrive so next time we can do just 2s fast reinstall on each runtime restart instead of 20 min whl compile\n",
        "# But. Because we can get different gpu next time. We need to compile and cache multiple whl files for each  gpu we encounter and save whls to gdrive in dirs with gpu names\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "%cd /content/svox2\n",
        "\n",
        "# grab currenly assigned gpu model name (P100-16gb etc.)\n",
        "gpuname = !nvidia-smi -L\n",
        "gpuname = str(gpuname).replace('PCIE-','').split('Tesla ')[1].split(' ')[0]\n",
        "whlname = 'svox2-0.0.1.dev0+sphtexcub.lincolor.fast-cp37-cp37m-linux_x86_64.whl'\n",
        "whlpath = '/content/drive/MyDrive/'+gpuname+'/'+whlname\n",
        "print(gpuname)\n",
        "\n",
        "# compile this whl just once first time to obtain and cache it on gdrive\n",
        "if not os.path.exists(whlpath):\n",
        "  !apt install ninja-build\n",
        "  %env MAX_JOBS=4\n",
        "  !python setup.py bdist_wheel &> /dev/null\n",
        "  !mkdir /content/drive/MyDrive/{gpuname}\n",
        "  !cp ./dist/{whlname} {whlpath}\n",
        "\n",
        "# install cached whl next time env is reset to skip costly recompilation\n",
        "if os.path.exists(whlpath):\n",
        "  !pip install {whlpath} --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y7_nqfcVSzzD"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'TanksAndTempleBG'\n",
        "experiment   = 'M60'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qxqjozeh2oy1"
      },
      "outputs": [],
      "source": [
        "# download super cool tank dataset if its dir is not already present\n",
        "import os\n",
        "%cd /content/svox2\n",
        "# Datasets: from gdrive folder where id is last folder name in url: https://drive.google.com/drive/folders/128yBriW1IG_3NJ5Rp7APSTZsJqdJdfc1\n",
        "gdrive_ids={'TanksAndTempleBG':'1PD4oTP4F8jTtpjd_AQjCsL4h8iYFCyvO', #\n",
        "            'nerf_llff_data'  :'16VnMcF1KJYxN9QId6TClMsZRahHNMW5g',\n",
        "            'nerf_real_360'   :'1jzggQ7IPaJJTKx9yLASWHrX8dXHnG5eB',\n",
        "            'nerf_synthetic'  :'18JxhpWD-4ZmuFKLzKlAw-w5PpzZxXOcG'}\n",
        "\n",
        "if not os.path.exists('/content/svox2/data/'+dataset_name):\n",
        "  console_output = !gdown --id {gdrive_ids[dataset_name]} \n",
        "  downloaded_filename = str(console_output).split('To: /content/svox2/')[1].split('\\'')[0]\n",
        "\n",
        "  !mkdir data  &> /dev/null\n",
        "  if '.zip'    in downloaded_filename:\n",
        "    !unzip  -q   {downloaded_filename} -d data\n",
        "  \n",
        "  if '.tar.gz' in downloaded_filename:\n",
        "    !tar   -xf   {downloaded_filename} -C data\n",
        "\n",
        "  # if needed, unify root data dir name and subdir structure since some tar based datasets \n",
        "  # are in aditional subdirs with unique names. but let's have just one root dir named \"data\"\n",
        "  if os.path.exists('/content/svox2/data/'+dataset_name):\n",
        "    !mv data/{dataset_name}/* data/\n",
        "\n",
        "  # remove huge downloaded no longer needed file. \n",
        "  !rm  -f  {downloaded_filename}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nqzaX9yKtRY6"
      },
      "outputs": [],
      "source": [
        "# TO DO: \n",
        "# enable this optional step to upload and colab calibrate your own images \n",
        "# and prepare dataset for svox2 to extract voxels via svox2\n",
        "# \n",
        "# %cd /content/svox2/opt/\n",
        "\n",
        "# !bash scripts/proc_colmap.sh video_to_obj\n",
        "\n",
        "# !python scripts/run_colmap.py video_to_obj\n",
        "# !python colmap2nsvf.py video_to_obj/sparse/0\n",
        "# !python create_split.py -y video_to_obj\n",
        "# !pip install nerfvis\n",
        "# !python scripts/view_data.py video_to_obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eG6WJ_aiV7KP"
      },
      "outputs": [],
      "source": [
        "# launch actual training (remember. 27g ram and 16g gpu for TanksAndTempleBG M60 dataset is needed if selected above)\n",
        "%cd /content/svox2/opt\n",
        "custom_configs={'TanksAndTempleBG':'tnt',\n",
        "                'nerf_llff_data'  :'llff',\n",
        "                'nerf_real_360'   :'llff',\n",
        "                'nerf_synthetic'  :'syn'}\n",
        "!./launch.sh {experiment} 0 ../data/{experiment} -c configs/{custom_configs[dataset_name]}.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RzGaIuArWuBy"
      },
      "outputs": [],
      "source": [
        "# since training runs detached we can peek at output on demand here when needed\n",
        "#\n",
        "# STOP THIS MANUALLY when training is done!!! when you see \"* Final eval and save\" line in output)\n",
        "# tail -f on itself will never end!!! \n",
        "%cd /content/svox2/opt\n",
        "!tail -f ckpt/{experiment}/log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DvAZ6a-xsaEZ"
      },
      "outputs": [],
      "source": [
        "# lets see our final resulting trained checkpoint file size when done . official one is 4G\n",
        "!ls -la /content/svox2/opt/ckpt/{experiment}/ckpt.npz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oGJD2CrXbHOH"
      },
      "outputs": [],
      "source": [
        "# backup our expensively trained experiment checkpoint to gdrive for future rendering tests even outside of colab if needed \n",
        "# or restore from gdrive if training pass above failed or was skipped\n",
        "import os\n",
        "%cd /content/svox2/opt\n",
        "!mkdir /content/drive/MyDrive/ckpt &> /dev/null\n",
        "\n",
        "# if training was succesfull and produced npz\n",
        "if os.path.exists('/content/svox2/opt/ckpt/'+experiment+'/ckpt.npz'):\n",
        "  print('backing ckpt '+experiment+' to gdrive')\n",
        "  !cp -rf /content/svox2/opt/ckpt/{experiment} /content/drive/MyDrive/ckpt\n",
        "\n",
        "# if not, or was skipped, let's restore checkpoint of this experiment from our gdrive if any is found\n",
        "else:\n",
        "  if os.path.exists('/content/drive/MyDrive/ckpt/'+experiment+'/ckpt.npz'):\n",
        "    print('loading ckpt '+experiment+' from gdrive')\n",
        "    !cp -rf /content/drive/MyDrive/ckpt/{experiment} /content/svox2/opt/ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eIUHJyMrQNxS"
      },
      "outputs": [],
      "source": [
        "# (Sadly even thou colab pro has 16gb, it is still just 16g gpu)\n",
        "# SO. If the damn training for too large datasets keeps failing with: out of memory \n",
        "#\n",
        "# Then. Luckily. We can still at least try download already trained checkpoints (thx. to paper authors ;D yay)\n",
        "# And at least start playing with rendering images from various angles\n",
        "#\n",
        "# BUT BEWARE this is 11g gz download if enabled\n",
        "# AND ALSO: if 3-4 downloads happen per 24h of this 11g large file from gdrive, which is highly plausible given usage in this colab. \n",
        "# Then google colab will block further downloads via this gdown api at this particular day for 24h\n",
        "# If that happens. You can still supposedly download it via browser and curl/wget or upload it here by other means I guess?\n",
        "\n",
        "%cd /content/svox2/opt\n",
        "import os\n",
        "\n",
        "# change this to True to enable pretrained checkpoints download. But beware again !!! 11gb file\n",
        "if False:\n",
        "  !mv ckpt ckpt_our\n",
        "  if not os.path.exists('ckpt_tnt.tar.gz'): \n",
        "    !gdown --id 1v9xb5Sd3ulofwNUynC71I_fdwnSLnFhS \n",
        "  !tar -xvf ckpt_tnt.tar.gz  &> /dev/null\n",
        "  !rm  -rf  ckpt_tnt.tar.gz # delete this huge 11g file as fast as possible\n",
        "  !ls -la tnt_equirectlin_fasttv_autoscale/M60/ckpt.npz # check ckpt size for m60. should be around 4g\n",
        "  !mv tnt_equirectlin_fasttv_autoscale ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "53KZA1Miqzp7"
      },
      "outputs": [],
      "source": [
        "# finally lets synthetize some sample images from various angles (typically 360 orbit around object) from trained checkpoint / model\n",
        "%cd /content/svox2/opt\n",
        "!python -u render_imgs.py ckpt/{experiment} ../data/{experiment} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T_DzNH_vj5Ja"
      },
      "outputs": [],
      "source": [
        "# transfer 3mb of jpgs in zip is more practical than 40mb pngs or hard to inspect mp4 with too aggresive compression\n",
        "%%capture \n",
        "%cd /content/svox2/opt/ckpt/{experiment}/test_renders\n",
        "!for i in *.png; do ffmpeg -i \"$i\" \"${i%.*}.jpg\" &> /dev/null ; done \n",
        "!find . -type f -iname \\*.png -delete\n",
        "%cd /content/svox2/opt\n",
        "!zip -rq images.zip /content/svox2/opt/ckpt/{experiment}/test_renders &> /dev/null "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y9F8BfCNZUxx"
      },
      "outputs": [],
      "source": [
        "# copy resulting images to special in html cell visible dir. since html gives bigger output preview flexibility\n",
        "%%capture \n",
        "!cp /content/svox2/opt/ckpt/{experiment}/test_renders/*.* /usr/local/share/jupyter/nbextensions/ &> /dev/null\n",
        "!cp images.zip /usr/local/share/jupyter/nbextensions/ &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZzAMVhVQYZX2"
      },
      "outputs": [],
      "source": [
        "# show some sample synthetized images\n",
        "%%html\n",
        "<a href src='/nbextensions/images.zip' download>Download Images</a><br>\n",
        "<img width=\"100%\" src='/nbextensions/0000.jpg' />\n",
        "<img width=\"100%\" src='/nbextensions/0020.jpg' />\n",
        "<img width=\"100%\" src='/nbextensions/0031.jpg' />"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Plenoxels.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}